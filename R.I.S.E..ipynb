{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.applications import VGG16\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.layers import Input\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "image_model = VGG16(include_top=True, weights='imagenet')\n",
    "\n",
    "VGG_last_layer = image_model.get_layer('fc2')\n",
    "vgg_model = Model(inputs = image_model.input, outputs = VGG_last_layer.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to extract features from input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_vector(path, size=(224,224,)):\n",
    "    img = Image.open(path)\n",
    "    img = img.resize(size=size,resample=Image.LANCZOS)\n",
    "    img = np.array(img)/255.0\n",
    "    if len(img.shape)==2:\n",
    "        img = np.repeat(img[:,:,np.newaxis], 3, axis=2)\n",
    "    image_batch = np.expand_dims(img, axis=0)\n",
    "    activations = vgg_model.predict(image_batch).reshape((4096,))\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building h5 file to store feature vectors of all images in database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = []\n",
    "files = od.listdir('./train2017')\n",
    "files.sort()\n",
    "for file in files:\n",
    "    activations = get_feature_vector('./train2017/'+file)\n",
    "    batch.append(activations)\n",
    "activation_file = h5py.File(\"vgg_activations.h5\",\"w\")\n",
    "activation_file.create_dataset('last_layer_activations',data=vgg_activations)\n",
    "activation_file.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the generated h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h5 file loaded\n"
     ]
    }
   ],
   "source": [
    "activation_file = h5py.File(\"vgg_activations.h5\",\"r\")\n",
    "fvec = list(activation_file['last_layer_activations'])\n",
    "fvec.append(features)\n",
    "print(\"h5 file loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking user input to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_image = input(\"Enter the image path:\")\n",
    "features = get_feature_vector(user_image)\n",
    "img = mpimg.imread(user_image)\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()\n",
    "print(\"Image feature vector loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying clustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('./train2017')\n",
    "files.sort()\n",
    "l=[]\n",
    "for i in range(0,118288,22578):\n",
    "    nn = NearestNeighbors(n_neighbors=1,algorithm='brute')\n",
    "    end = i+22578\n",
    "    if end>118287:\n",
    "        end = 118287\n",
    "    nn.fit(fvec[i:end])\n",
    "    neigh = nn.kneighbors(X=np.array([features]),return_distance=False)[0][0]\n",
    "    l.append(files[i+neigh])\n",
    "    print(l[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in l:\n",
    "    img = mpimg.imread('./train2017/'+img)\n",
    "    imgplot = plt.imshow(img)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
